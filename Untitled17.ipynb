{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP8my0lfcpcSyh//8ywd9yv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/2303a51329/NLP/blob/main/Untitled17.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_yXSq4Ce8wPu",
        "outputId": "8aeb25db-3ef5-4f9c-c6d2-97482819ab12"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset shape: (516, 4)\n",
            "\n",
            "Columns: Index(['test_id', 'description_x', 'description_y', 'same_security'], dtype='object')\n",
            "\n",
            "First 5 text_1 entries:\n",
            " 0                          semtech corp\n",
            "1                vanguard mid cap index\n",
            "2           spdr gold trust gold shares\n",
            "3         vanguard total bond index adm\n",
            "4    oakmark international fund class i\n",
            "Name: description_x, dtype: object\n",
            "\n",
            "Null values after cleaning: 0\n"
          ]
        }
      ],
      "source": [
        "#Task 1\n",
        "import pandas as pd\n",
        "import re\n",
        "import spacy\n",
        "\n",
        "# Load the dataset (Assuming the file is named 'train.csv')\n",
        "df = pd.read_csv('/content/test.csv')\n",
        "\n",
        "# Inspect the structure\n",
        "print(\"Dataset shape:\", df.shape)\n",
        "print(\"\\nColumns:\", df.columns)\n",
        "\n",
        "# Display first 5 entries of 'text_1'\n",
        "print(\"\\nFirst 5 text_1 entries:\\n\", df['description_x'].head())\n",
        "\n",
        "# Clean null values\n",
        "df = df.dropna(subset=['description_x'])\n",
        "print(\"\\nNull values after cleaning:\", df['description_x'].isnull().sum())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Task-2:POS tagging with spaCy\n",
        "!python -m spacy download en_core_web_sm\n",
        "\n",
        "\n",
        "# Load spaCy model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Take first 5 entries from 'description_x'\n",
        "sentences = df['description_x'].head(5).tolist()\n",
        "\n",
        "for idx, sentence in enumerate(sentences, 1):\n",
        "    print(f\"\\nSentence {idx}: {sentence}\")\n",
        "    doc = nlp(sentence)\n",
        "\n",
        "    nouns = [token.text for token in doc if token.pos_ == \"NOUN\"]\n",
        "    verbs = [token.text for token in doc if token.pos_ == \"VERB\"]\n",
        "    adjectives = [token.text for token in doc if token.pos_ == \"ADJ\"]\n",
        "\n",
        "    print(\"Nouns:\", nouns)\n",
        "    print(\"Verbs:\", verbs)\n",
        "    print(\"Adjectives:\", adjectives)\n",
        "\n",
        "# Q2: Regex Cleaning - Remove phone, email, URLs, special chars\n",
        "texts = [\n",
        "    \"My phone number is 1234567890 and my email is test@domain.com\",\n",
        "    \"Visit https://example.com for more info!!!\",\n",
        "    \"HELLO!!! This is SOOOOO exciting :))\",\n",
        "    \"Contact us at info@company.org or call +91 98765-43210\",\n",
        "    \"Python's regex is very useful!!!  #Coding #Fun\"\n",
        "]\n",
        "\n",
        "cleaned_texts = []"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aI6PK_QCDvMf",
        "outputId": "c8282aa3-789e-43e9-9be5-68a68fb9b3a1"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting en-core-web-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m91.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n",
            "\n",
            "Sentence 1: semtech corp\n",
            "Nouns: []\n",
            "Verbs: []\n",
            "Adjectives: []\n",
            "\n",
            "Sentence 2: vanguard mid cap index\n",
            "Nouns: ['index']\n",
            "Verbs: []\n",
            "Adjectives: []\n",
            "\n",
            "Sentence 3: spdr gold trust gold shares\n",
            "Nouns: ['spdr', 'gold', 'trust', 'gold', 'shares']\n",
            "Verbs: []\n",
            "Adjectives: []\n",
            "\n",
            "Sentence 4: vanguard total bond index adm\n",
            "Nouns: ['index']\n",
            "Verbs: []\n",
            "Adjectives: []\n",
            "\n",
            "Sentence 5: oakmark international fund class i\n",
            "Nouns: ['fund', 'class']\n",
            "Verbs: []\n",
            "Adjectives: ['international']\n"
          ]
        }
      ]
    }
  ]
}