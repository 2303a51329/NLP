{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPA9hzKlCdOMNm4ILoB9sNR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/2303a51329/NLP/blob/main/Untitled14.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nitk\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download(\"punkt\")\n",
        "nltk.download(\"punkt_tab\")\n",
        "sentence = \"I wake up at 7:00 o'clock. I had my breakfast and then I went to the college on foot. After checking the timetable, I went to room no. 3111. The class will be NLP. I took a seat. My faculty started the intro.\"\n",
        "tokens = word_tokenize(sentence)\n",
        "print(tokens)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bUCIXkQyxjVP",
        "outputId": "53e817c2-b3fc-4c43-c1fb-fbdaea37a334"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nitk\n",
            "  Downloading nitk-0.1-py3-none-any.whl.metadata (1.6 kB)\n",
            "Downloading nitk-0.1-py3-none-any.whl (15 kB)\n",
            "Installing collected packages: nitk\n",
            "Successfully installed nitk-0.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['I', 'wake', 'up', 'at', '7:00', \"o'clock\", '.', 'I', 'had', 'my', 'breakfast', 'and', 'then', 'I', 'went', 'to', 'the', 'college', 'on', 'foot', '.', 'After', 'checking', 'the', 'timetable', ',', 'I', 'went', 'to', 'room', 'no', '.', '3111', '.', 'The', 'class', 'will', 'be', 'NLP', '.', 'I', 'took', 'a', 'seat', '.', 'My', 'faculty', 'started', 'the', 'intro', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "length = len(tokens)\n",
        "print(length)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J4T-4nFqzEkR",
        "outputId": "4a8fcdb8-b939-411b-be24-bfa61dd2eb3f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "51\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nitk\n",
        "import nltk\n",
        "from nltk.corpus  import stopwords\n",
        "nltk.download(\"stopwords\")\n",
        "stop_words = set(stopwords.words(\"english\"))\n",
        "filtered_tokens = [token for token in tokens if token.lower() not in stop_words]\n",
        "print(filtered_tokens)\n",
        "sentence2=\"i have a friend with short hair she always cuts her hair for her canveneance and she ware able make up her own and she was the frendly company for me always\"\n",
        "length = len(tokens)\n",
        "print(length)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pUMT5BVY0a_g",
        "outputId": "af73d99f-2ac3-45ce-dcbc-c48784586a1e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nitk in /usr/local/lib/python3.11/dist-packages (0.1)\n",
            "['wake', '7:00', \"o'clock\", '.', 'breakfast', 'went', 'college', 'foot', '.', 'checking', 'timetable', ',', 'went', 'room', '.', '3111', '.', 'class', 'NLP', '.', 'took', 'seat', '.', 'faculty', 'started', 'intro', '.']\n",
            "51\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import nltk.stem as stemmer\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "aol=\"Running quickly through the forest, the children happily played, jumping, shouting, and laughing. Their voices echoed, and the joyful sounds carried far, reminding everyone that happiness often comes from sharing simple moments and creating lasting memories\"\n",
        "stemmer = PorterStemmer()\n",
        "tokens = word_tokenize(aol)\n",
        "stemmed_words = [stemmer.stem(word) for word in tokens]\n",
        "print( tokens)\n",
        "print(stemmed_words)"
      ],
      "metadata": {
        "id": "Q4DCjmZh95Op",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "631174bd-6ef5-4162-dfc5-6068d3b34609"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Running', 'quickly', 'through', 'the', 'forest', ',', 'the', 'children', 'happily', 'played', ',', 'jumping', ',', 'shouting', ',', 'and', 'laughing', '.', 'Their', 'voices', 'echoed', ',', 'and', 'the', 'joyful', 'sounds', 'carried', 'far', ',', 'reminding', 'everyone', 'that', 'happiness', 'often', 'comes', 'from', 'sharing', 'simple', 'moments', 'and', 'creating', 'lasting', 'memories']\n",
            "['run', 'quickli', 'through', 'the', 'forest', ',', 'the', 'children', 'happili', 'play', ',', 'jump', ',', 'shout', ',', 'and', 'laugh', '.', 'their', 'voic', 'echo', ',', 'and', 'the', 'joy', 'sound', 'carri', 'far', ',', 'remind', 'everyon', 'that', 'happi', 'often', 'come', 'from', 'share', 'simpl', 'moment', 'and', 'creat', 'last', 'memori']\n"
          ]
        }
      ]
    }
  ]
}